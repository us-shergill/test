import requests
import json
import logging
import os
from airflow.models import Variable
from datetime import datetime,timezone
from requests.auth import HTTPBasicAuth
from google.cloud import bigquery

# Set your username and password
logger = logging.getLogger("airflow.task")
collibra_hostnames = {"dev": "arvest-dev.collibra.com", "test": "arvest-dev.collibra.com","prod": "arvest.collibra.com"}
ENVIRONMENT = os.environ.get("DBT_ENVIRONMENT")
COLLIBRA_URL_HOSTNAME = collibra_hostnames[ENVIRONMENT]
COLLIBRA_USERNAME = "svc_dataplatform_collibra_metadata"
COLLIBRA_PASSWORD = Variable.get("collibra_password")
PROJECT = os.environ.get("PROJECTID")

def collibra_pii_sync():
    project_id = PROJECT
    # Set the BigQuery table and metadata table names
    bq_table_name = f"{project_id}.landing_collibra.asset_classified"
    metadata_table = f"{project_id}.landing_collibra.metadata"

    # Create a BigQuery client
    bq_client = bigquery.Client(project=project_id)

    # Fetch the last processed timestamp from metadata table
    metadata_query = "SELECT last_processed_timestamp FROM `{}` WHERE id='last_updated'".format(metadata_table)
    metadata_results = list(bq_client.query(metadata_query).result())

    if metadata_results:
        last_timestamp = metadata_results[0].last_processed_timestamp
    else:
        # Default timestamp if the metadata table doesn't have an entry yet
        last_timestamp = datetime.strptime("2023-01-01 00:00:00", "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)

    bq_query = "SELECT * FROM `{}` WHERE last_modified_timestamp >= TIMESTAMP('{}') LIMIT 2".format(bq_table_name, last_timestamp)

    # Query the BigQuery table
    bq_results = bq_client.query(bq_query).result()

    # Create a Collibra payload from the BigQuery results
    collibra_payload = []
    new_last_timestamp = last_timestamp
    for row in bq_results:
        parsed_payload = json.loads(row.json_payload)
        value = "Yes" if "is_pii" in parsed_payload and parsed_payload["is_pii"] else "No"
        asset_data = {
            "assetId": row.asset_id,
            "typeId": parsed_payload["assettype"]["asset_type_id"],
            "value": value
        }
        print(asset_data)
        collibra_payload.append(asset_data)
        
        if row.last_modified_timestamp > new_last_timestamp:
            new_last_timestamp = row.last_modified_timestamp

    response = requests.post(
        "https://developer.collibra.com/rest/2.0/attributes/bulk",
        auth=HTTPBasicAuth(COLLIBRA_USERNAME, COLLIBRA_PASSWORD),
        headers={"Accept": "application/json", "Content-Type": "application/json"},
        json=collibra_payload)

    # Check the response status code
    if response.status_code == 200:
        # Success! Update the last processed timestamp in metadata table
        if metadata_results:
            # Update existing timestamp
            update_query = """
            UPDATE `{}` SET last_processed_timestamp = TIMESTAMP('{}') WHERE id='last_updated'
            """.format(metadata_table, new_last_timestamp)
        else:
            # Insert new timestamp
            update_query = """
            INSERT INTO `{}` (id, last_processed_timestamp) VALUES('last_updated', TIMESTAMP('{}'))
            """.format(metadata_table, new_last_timestamp)
        
        bq_client.query(update_query).result()
        print("Attributes sent to Collibra successfully!")
    else:
        # An error occurred
        print(f"Error: {response.status_code}")
        print(response.content)

